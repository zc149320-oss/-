import streamlit as st
import pandas as pd
import requests
import time
from datetime import datetime, timedelta
import numpy as np
from sklearn.neural_network import MLPRegressor
from sklearn.preprocessing import StandardScaler
# --- 1. è®¿é—®å¯†ç ä¿æŠ¤ ---
def check_password():
    def password_entered():
        if st.session_state["password"] == "666888":
            st.session_state["password_correct"] = True
            del st.session_state["password"]
        else:
            st.session_state["password_correct"] = False

    if "password_correct" not in st.session_state:
        st.text_input("è¯·è¾“å…¥å®æˆ˜æˆæƒç ", type="password", on_change=password_entered, key="password")
        st.warning("ğŸ”’ æ­¤ç³»ç»Ÿå—ä¿æŠ¤ï¼Œä»…é™å†…éƒ¨ä½¿ç”¨")
        return False
    elif not st.session_state["password_correct"]:
        st.text_input("è¯·è¾“å…¥å®æˆ˜æˆæƒç ", type="password", on_change=password_entered, key="password")
        st.error("âŒ å¯†ç é”™è¯¯ï¼Œè¯·é‡æ–°è¾“å…¥")
        return False
    else:
        return True

if not check_password():
    st.stop()
    import streamlit as st
import pandas as pd
import requests
import time
from datetime import datetime, timedelta
import numpy as np
from sklearn.neural_network import MLPRegressor
from sklearn.preprocessing import StandardScaler

# --- 1. æ·±åº¦è¿›åŒ– AI å¼•æ“ ---
class ProNeuralEngine:
    def __init__(self):
        self.scaler = StandardScaler()

    def train_model(self, df):
        """æ ¸å¿ƒï¼šä¸¥æ ¼çš„æ—¶é—´åºåˆ—æ»‘çª—è®­ç»ƒ"""
        if len(df) < 150: return None
        # ç¡®ä¿æ•°æ®ä¸¥æ ¼æŒ‰æ—¶é—´ä»æ—§åˆ°æ–°æ’åˆ—
        data = df[['å† å†›', 'äºšå†›', 'å† äºšå’Œ']].iloc[::-1].values
        window = 30 # å¢åŠ çª—å£æ·±åº¦ï¼Œæå‡é•¿çº¿é¢„æµ‹ç¨³å¥åº¦
        X, y = [], []
        for i in range(len(data) - window):
            X.append(data[i:i+window].flatten())
            y.append(data[i+window, 2]) # é¢„æµ‹å† äºšå’Œ
        
        X_scaled = self.scaler.fit_transform(X)
        # é‡‡ç”¨æœ€å¹³è¡¡çš„éšè—å±‚é…ç½®ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
        model = MLPRegressor(hidden_layer_sizes=(128, 64, 32), max_iter=1000, random_state=42, tol=1e-4)
        model.fit(X_scaled, y)
        return model

    def predict_next(self, df, model):
        """ç²¾å‡†å¯¹ä½é¢„æµ‹ä¸‹ä¸€æœŸ"""
        try:
            # è¿™é‡Œçš„ next_issue å¿…é¡»æ˜¯ä¸¥æ ¼çš„ä¸Šä¸€æœŸ + 1
            last_issue_val = int(df['æœŸå·'].iloc[0])
            next_issue = str(last_issue_val + 1)
            
            # æå–æœ€æ¥è¿‘ç°åœ¨çš„ 30 æœŸç‰¹å¾
            latest_feat = df[['å† å†›', 'äºšå†›', 'å† äºšå’Œ']].head(30).iloc[::-1].values.flatten()
            latest_scaled = self.scaler.transform([latest_feat])
            pred_sum = model.predict(latest_scaled)[0]
            
            # ç§‘å­¦ç½®ä¿¡åº¦ï¼šè·ç¦»æ•´æ•°è¶Šè¿‘ï¼Œè§„å¾‹æ€§è¶Šå¼º
            dist = abs(pred_sum - round(pred_sum))
            confidence = round(0.55 + (0.35 * (1 - dist * 2)), 2)
            
            # å†³ç­–åˆ†æ”¯
            sum_target = "å•" if int(round(pred_sum)) % 2 != 0 else "åŒ"
            # å† å†›ä½é€»è¾‘ï¼šAI é¢„æµ‹å’Œå€¼åå¤§æ—¶ï¼Œå† å†›é€šå¸¸ä¹Ÿåå¤§
            c1_target = "å¤§" if pred_sum > 11 else "å°"
            
            return confidence, f"å† å†›-{c1_target}", f"å’Œå€¼-{sum_target}", next_issue
        except Exception as e:
            return 0.50, "æ— æ³•é¢„æµ‹", "æ— æ³•é¢„æµ‹", "ç­‰å¾…æ•°æ®..."

# --- 2. å®æ—¶æ•°æ®æŠ“å– (å¸¦æ ¡éªŒæœºåˆ¶) ---
@st.cache_data(ttl=5) # æçŸ­ç¼“å­˜ï¼Œä¿è¯æ•°æ®æ–°é²œåº¦
def fetch_live_data():
    all_rows = []
    # æŠ“å– 3 å¤©æ•°æ®ç¡®ä¿è®­ç»ƒé›†å¤Ÿåš
    for i in range(3):
        t_date = (datetime.now() - timedelta(days=i)).strftime('%Y-%m-%d')
        url = "https://api.apiose122.com/pks/getPksHistoryList.do"
        params = {"lotCode": "10037", "date": t_date, "pageSize": "1000"}
        try:
            resp = requests.get(url, params=params, timeout=10)
            if resp.status_code == 200:
                data_list = resp.json().get('result', {}).get('data', [])
                for item in data_list:
                    codes = item.get('preDrawCode', "").split(',')
                    if len(codes) < 2: continue
                    c1, c2 = int(codes[0]), int(codes[1])
                    all_rows.append({
                        "æœŸå·": str(item.get('preDrawIssue')),
                        "å† å†›": c1, "äºšå†›": c2, "å† äºšå’Œ": c1 + c2,
                        "å•åŒ": "åŒ" if (c1 + c2) % 2 == 0 else "å•",
                        "å¤§å°": "å¤§" if c1 > 5 else "å°"
                    })
        except: continue
    if not all_rows: return pd.DataFrame()
    return pd.DataFrame(all_rows).drop_duplicates(subset=['æœŸå·']).sort_values(by='æœŸå·', ascending=False)
# --- 3. ç•Œé¢å±•ç°ä¸â€œé›¶è¯¯å·®â€ç»“ç®—ç³»ç»Ÿ ---
st.set_page_config(page_title="AI ç¥ç»ç½‘ç»œ-æœ€ç»ˆä¼˜åŒ–ç‰ˆ", layout="wide")

# æŒä¹…åŒ–çŠ¶æ€åˆå§‹åŒ–
if 'history_log' not in st.session_state: st.session_state.history_log = []
if 'profit' not in st.session_state: st.session_state.profit = 0.0
if 'pending_bet' not in st.session_state: st.session_state.pending_bet = None

st.sidebar.header("ğŸ“Š å®æˆ˜ç»Ÿè®¡ä¸­å¿ƒ")
init_bal = st.sidebar.number_input("è®¾ç½®èµ·å§‹æ€»åˆ†", value=1000.0)
curr_bal = init_bal + st.session_state.profit

# è®¡ç®—å®æ—¶èƒœç‡
logs = st.session_state.history_log
total_r = len(logs)
wins = len([l for l in logs if "ğŸŸ¢" in l['çŠ¶æ€']])
win_rate = (wins / total_r * 100) if total_r > 0 else 0

st.sidebar.metric("ç´¯è®¡å®æˆ˜ç›ˆäº", f"{st.session_state.profit:.2f}", delta=f"{st.session_state.profit:.2f}")
st.sidebar.metric("å®æˆ˜æ€»èƒœç‡", f"{win_rate:.1f}%")

if st.sidebar.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰è®°å½•"):
    st.session_state.history_log = []
    st.session_state.profit = 0.0
    st.rerun()

st.title("ğŸ§  ç¥ç»ç½‘ç»œ - é«˜èƒœç‡å®æˆ˜å†³ç­–æ¨¡å‹")

df = fetch_live_data()
if not df.empty:
    latest_issue = df['æœŸå·'].iloc[0]
    
    # ã€æ ¸å¿ƒï¼šç²¾å‡†æœŸå·å¯¹ä½ç»“ç®—ã€‘
    if st.session_state.pending_bet:
        bet = st.session_state.pending_bet
        # åªæœ‰å½“æœ€æ–°å¼€å¥–æœŸå·ç­‰äºæˆ–å¤§äºæˆ‘ä»¬çš„ç›®æ ‡æœŸå·æ—¶ï¼Œæ‰è§¦å‘ç»“ç®—
        match_row = df[df['æœŸå·'] == bet['target']]
        if not match_row.empty:
            res = match_row.iloc[0]
            gain = 0.0
            # å† å†›ä½
            c1_win = res['å¤§å°'] == bet['c1'].split('-')[1]
            gain += bet['amt'] * 0.989 if c1_win else -bet['amt']
            # å’Œå€¼ä½ (å•åŒèµ”ç‡åŒºåˆ†)
            ds_target = bet['sum'].split('-')[1]
            ds_win = res['å•åŒ'] == ds_target
            ds_odds = 1.2 if ds_target == "åŒ" else 0.79 
            gain += bet['amt'] * ds_odds if ds_win else -bet['amt']
            
            # è®°å½•å†å²
            st.session_state.history_log.insert(0, {
                "æœŸå·": bet['target'], "é¢„æµ‹å†…å®¹": f"{bet['c1']} | {bet['sum']}",
                "åˆ†å€¼": bet['amt'], "å®é™…ç»“æœ": f"{res['å¤§å°']} | {res['å•åŒ']}",
                "ç›ˆäº": round(gain, 2), "çŠ¶æ€": "ğŸŸ¢ è·åˆ©" if gain > 0 else "ğŸ”´ äºæŸ",
                "æ—¶é—´": datetime.now().strftime("%H:%M:%S")
            })
            st.session_state.profit += gain
            st.session_state.pending_bet = None
            st.toast(f"æœŸå· {bet['target']} ç»“ç®—å®Œæˆï¼")
            st.rerun()

    # è¿è¡Œæ¨¡å‹
    engine = ProNeuralEngine()
    with st.spinner('æ­£åœ¨åˆ†æ 3000 æœŸå¤§æ•°æ®ç‰¹å¾...'):
        model = engine.train_model(df)
    
    conf, c1_adv, sum_adv, next_iss = engine.predict_next(df, model)
    
    # æ™ºèƒ½åˆ†æ¡£ï¼šç½®ä¿¡åº¦ä½äº 60% ç»ä¸ä¸‹æ³¨
    bet_amt = 0
    if conf >= 0.72: bet_amt = int(curr_bal * 0.1)
    elif conf >= 0.65: bet_amt = int(curr_bal * 0.05)
    
    if bet_amt > 0 and not st.session_state.pending_bet:
        # ç¡®ä¿ä¸é‡å¤å¯¹åŒä¸€æœŸä¸‹æ³¨
        if not logs or logs[0]['æœŸå·'] != next_iss:
            st.session_state.pending_bet = {"target": next_iss, "amt": bet_amt, "c1": c1_adv, "sum": sum_adv}

    # è§†è§‰é¢æ¿
    c1, c2, c3 = st.columns(3)
    c1.metric("AI ç½®ä¿¡åº¦", f"{conf*100:.1f}%")
    c2.metric("ğŸ¯ é¢„æµ‹ç›®æ ‡", f"{next_iss}æœŸ")
    c3.success(f"å·²åŠ è½½æœ‰æ•ˆæ ·æœ¬: {len(df)}æœŸ")

    if bet_amt > 0:
        st.error(f"### ğŸš€ AI å®æˆ˜æŒ‡ä»¤ï¼šé’ˆå¯¹ã€{next_iss}ã€‘æœŸ")
        st.write(f"å»ºè®®å…¥åœºåˆ†å€¼ï¼š{bet_amt} | æ–¹å‘ï¼š{c1_adv} & {sum_adv}")
    else:
        st.info(f"### ğŸ“‹ ã€{next_iss}ã€‘æœŸè§‚æœ›ï¼šæ¨¡å‹åˆ¤å®šå½“å‰è§„å¾‹æ€§è¾ƒå¼±")

    st.divider()
    st.subheader("ğŸ“ å†å²ä¸‹æ³¨å®æˆ˜æ—¥å¿— (ä¸¥æ ¼æœŸå·åŒ¹é…)")
    if st.session_state.history_log:
        st.table(pd.DataFrame(st.session_state.history_log).head(15))
    
    st.divider()
    st.write("### ğŸ“œ æœ€æ–°æ•°æ®åŸå§‹èµ°åŠ¿")
    st.table(df.head(10))
    time.sleep(5)
    st.rerun()
