import streamlit as st
import pandas as pd
import requests
import time
from datetime import datetime, timedelta
import numpy as np
from sklearn.neural_network import MLPRegressor
from sklearn.preprocessing import StandardScaler

# --- 1. è®¿é—®å¯†ç ä¿æŠ¤ ---
def check_password():
    def password_entered():
        if st.session_state["password"] == "666888":
            st.session_state["password_correct"] = True
            del st.session_state["password"]
        else:
            st.session_state["password_correct"] = False

    if "password_correct" not in st.session_state:
        st.text_input("è¯·è¾“å…¥å®æˆ˜æˆæƒç ", type="password", on_change=password_entered, key="password")
        st.warning("ğŸ”’ æ­¤ç³»ç»Ÿå—ä¿æŠ¤ï¼Œä»…é™å†…éƒ¨ä½¿ç”¨")
        return False
    elif not st.session_state["password_correct"]:
        st.text_input("è¯·è¾“å…¥å®æˆ˜æˆæƒç ", type="password", on_change=password_entered, key="password")
        st.error("âŒ å¯†ç é”™è¯¯ï¼Œè¯·é‡æ–°è¾“å…¥")
        return False
    else:
        return True

if not check_password():
    st.stop()

# --- 2. æ·±åº¦è¿›åŒ– AI å¼•æ“ ---
class ProNeuralEngine:
    def __init__(self):
        self.scaler = StandardScaler()

    def train_model(self, df):
        if len(df) < 50: return None
        data = df[['å† å†›', 'äºšå†›', 'å† äºšå’Œ']].iloc[::-1].values
        window = 10 
        X, y = [], []
        for i in range(len(data) - window):
            X.append(data[i:i+window].flatten())
            y.append(data[i+window, 2])
        X_scaled = self.scaler.fit_transform(X)
        model = MLPRegressor(hidden_layer_sizes=(64, 32), max_iter=500, random_state=42)
        model.fit(X_scaled, y)
        return model

    def predict_next(self, df, model):
        try:
            last_issue_val = int(df['æœŸå·'].iloc[0])
            next_issue = str(last_issue_val + 1)
            latest_feat = df[['å† å†›', 'äºšå†›', 'å† äºšå’Œ']].head(10).iloc[::-1].values.flatten()
            latest_scaled = self.scaler.transform([latest_feat])
            pred_sum = model.predict(latest_scaled)[0]
            confidence = 0.68
            sum_target = "å•" if int(round(pred_sum)) % 2 != 0 else "åŒ"
            c1_target = "å¤§" if pred_sum > 11 else "å°"
            return confidence, f"å† å†›-{c1_target}", f"å’Œå€¼-{sum_target}", next_issue
        except:
            return 0.50, "è®¡ç®—ä¸­", "è®¡ç®—ä¸­", "---"
            # --- 3. 1680610 ä¸“å±æ•°æ®æŠ“å–å¼•æ“ ---
@st.cache_data(ttl=10)
def fetch_live_data():
    all_rows = []
    # ä½¿ç”¨æ–°æ¥å£ï¼š1680610 çš„æé€Ÿèµ›è½¦æ•°æ®æ¥å£
    url = "https://api.pks10.com/pks/getPksHistoryList.do" # è¯¥åŸŸåä¸º 168 å®˜ç½‘åå°æ•°æ®æº
    params = {
        "lotCode": "10037", 
        "date": datetime.now().strftime('%Y-%m-%d'),
        "pageSize": "50"
    }
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
        "Referer": "https://1680610.com/"
    }
    try:
        resp = requests.get(url, params=params, headers=headers, timeout=10)
        if resp.status_code == 200:
            json_data = resp.json()
            data_list = json_data.get('result', {}).get('data', [])
            for item in data_list:
                codes = item.get('preDrawCode', "").split(',')
                if len(codes) < 2: continue
                c1, c2 = int(codes[0]), int(codes[1])
                all_rows.append({
                    "æœŸå·": str(item.get('preDrawIssue')),
                    "å† å†›": c1, "äºšå†›": c2, "å† äºšå’Œ": c1 + c2,
                    "å•åŒ": "åŒ" if (c1 + c2) % 2 == 0 else "å•",
                    "å¤§å°": "å¤§" if c1 > 5 else "å°"
                })
    except Exception as e:
        st.sidebar.error(f"168æ¥å£è¿æ¥å¼‚å¸¸: {str(e)}")
    
    if not all_rows: return pd.DataFrame()
    return pd.DataFrame(all_rows).drop_duplicates(subset=['æœŸå·']).sort_values(by='æœŸå·', ascending=False)

# --- 4. ç•Œé¢å±•ç¤º (é’ˆå¯¹ç”µè„‘ç‰ˆä¼˜åŒ–) ---
st.set_page_config(page_title="AIç³»ç»Ÿ-168å¢å¼ºç‰ˆ", layout="wide")
if 'history_log' not in st.session_state: st.session_state.history_log = []
if 'profit' not in st.session_state: st.session_state.profit = 0.0

with st.sidebar:
    st.header("ğŸ“Š å®æˆ˜ç»Ÿè®¡ä¸­å¿ƒ")
    st.metric("å®æ—¶ç›ˆäº", f"{st.session_state.profit:.2f}")
    if st.button("ğŸ—‘ï¸ é‡ç½®æ•°æ®"):
        st.session_state.history_log = []
        st.session_state.profit = 0.0
        st.rerun()

st.title("ğŸ§  ç¥ç»ç½‘ç»œ - é«˜èƒœç‡å®æˆ˜å†³ç­–æ¨¡å‹")
st.write(f"æ•°æ®æ¥æºï¼š168å®æ—¶æ•°æ®ç½‘ | æ›´æ–°æ—¶é—´ï¼š{datetime.now().strftime('%H:%M:%S')}")

df = fetch_live_data()

if df.empty:
    st.warning("ğŸ”„ æ­£åœ¨ä» 168 æ•°æ®ä¸­å¿ƒæ‹‰å–æœ€æ–°å¼€å¥–ç»“æœï¼Œè¯·ç¨å€™...")
    time.sleep(2)
    st.rerun()
else:
    engine = ProNeuralEngine()
    model = engine.train_model(df)
    conf, c1_adv, sum_adv, next_iss = engine.predict_next(df, model)
    
    # é¡¶éƒ¨æ•°æ®çœ‹æ¿
    col1, col2, col3 = st.columns(3)
    col1.metric("AI ç½®ä¿¡åº¦", f"{conf*100:.1f}%")
    col2.metric("ğŸ¯ é¢„æµ‹ç›®æ ‡", next_iss)
    col3.success(f"168æ•°æ®å·²å¯¹é½: {len(df)}æœŸ")
    
    st.error(f"### ğŸš€ ä¸‹ä¸€æœŸæŒ‡ä»¤ã€{next_iss}ã€‘ï¼š{c1_adv} | {sum_adv}")
    
    st.divider()
    st.subheader("ğŸ“ è¿‘æœŸå®æˆ˜å¯¹ä½æ—¥å¿—")
    if st.session_state.history_log:
        st.table(pd.DataFrame(st.session_state.history_log).head(10))
    else:
        st.info("ç­‰å¾…é¦–æœŸç»“ç®—ä¸­... åªè¦å¼€å¥–å·æ›´æ–°ï¼Œæ­¤å¤„å°†è‡ªåŠ¨è®°å½•ç›ˆäºã€‚")
    
    st.write("### ğŸ“œ 168 æœ€æ–°èµ°åŠ¿å¿«ç…§")
    st.table(df.head(10))

time.sleep(10)
st.rerun()
